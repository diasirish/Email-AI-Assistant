{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Update Dear Dias,\\r\\n\\r\\nHow are you? Are you ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\r\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Re: Enquiry #959 - Dias Irishev - 12/02/2011 1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shipping of glasses Dear Dias,\\r\\n\\r\\n \\r\\n\\r\\...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\r\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Update Dear Dias,\\r\\n\\r\\nHow are you? Are you ...      1\n",
       "1                                               \\r\\n      1\n",
       "2  Re: Enquiry #959 - Dias Irishev - 12/02/2011 1...      1\n",
       "3  Shipping of glasses Dear Dias,\\r\\n\\r\\n \\r\\n\\r\\...      1\n",
       "4                                               \\r\\n      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_emails(folder, label):\n",
    "    data = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith('.json'):\n",
    "            with open(os.path.join(folder, filename), 'r') as f:\n",
    "                email = json.load(f)\n",
    "                text = email.get('subject', '') + ' ' + email.get('text_body', '')\n",
    "                data.append({'text': text, 'label': label})\n",
    "    return data\n",
    "\n",
    "# Load emails that need a reply\n",
    "replied_emails = load_emails('data_mail1/replied/', 1)\n",
    "replied_emails\n",
    "\n",
    "# Load emails that don't need a reply\n",
    "unreplied_emails = load_emails('data_mail1/unreplied/', 0)\n",
    "unreplied_emails\n",
    "\n",
    "# Load emails that need a reply\n",
    "replied_emails_2 = load_emails('data_mail2/replied/', 1)\n",
    "replied_emails\n",
    "\n",
    "# Load emails that don't need a reply\n",
    "unreplied_emails_2 = load_emails('data_mail2/unreplied/', 0)\n",
    "unreplied_emails\n",
    "\n",
    "# Combine and create a DataFrame\n",
    "all_emails = replied_emails + unreplied_emails + replied_emails_2 + unreplied_emails_2\n",
    "df = pd.DataFrame(all_emails)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vs/k0_1ms5n4xn7kr58dhzdsz0w0000gn/T/ipykernel_62074/1657956996.py:8: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(text, \"html.parser\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>update dear dias, how are you? are you ready f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>re enquiry 959 dias irishev 12022011 1720 hi d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shipping of glasses dear dias, i hope you are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  update dear dias, how are you? are you ready f...      1\n",
       "1                                                         1\n",
       "2  re enquiry 959 dias irishev 12022011 1720 hi d...      1\n",
       "3  shipping of glasses dear dias, i hope you are ...      1\n",
       "4                                                         1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "\n",
    "\n",
    "def clean_email(text):\n",
    "    # Parse and remove HTML tags using BeautifulSoup\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    text = soup.get_text()\n",
    "\n",
    "    # Normalize Unicode characters to remove unwanted symbols\n",
    "    text = unicodedata.normalize('NFKD', text)\n",
    "\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "\n",
    "    # Remove special characters, including emojis, and HTML artifacts\n",
    "    text = re.sub(r'[üî•*]', '', text)  # Remove specific special characters\n",
    "    text = re.sub(r'\\[del:.*?:del\\]', '', text)  # Remove text between [DEL: ... :DEL]\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)  # Remove other square-bracketed items (e.g., [1], [2])\n",
    "\n",
    "    # Remove escape characters and excessive whitespace\n",
    "    text = re.sub(r'\\r\\n|\\n|\\t', ' ', text)  # Replace escape characters with space\n",
    "\n",
    "    # Remove mentions of 'image' or placeholders\n",
    "    text = re.sub(r'\\bimage\\b', '', text)\n",
    "\n",
    "    # Remove non-Cyrillic, non-alphanumeric characters except basic punctuation\n",
    "    text = re.sub(r'[^–∞-—è–ê-–Øa-zA-Z0-9,.!?@+ ]+', '', text)\n",
    "\n",
    "    # Remove redundant spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "# Example usage\n",
    "df['text'] = df['text'].apply(clean_email)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18612,), (18612,))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['text'], df['label'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('michael webbs secrets of blissful relationships no! x o x o x o x o x o x o secrets of blissful relationships from michael webb, the webs 1 relationship author and expert x o x o x o x o x o x o no! by michael webb no was once a very popular word in our house when we had toddlers. we had little problem telling our son and daugher no to things that are potentially harmful. thats what loving parents do. however, many of us are unable to utter that twoletter word to our spouse. we dont want to upset the apple cart. we dont want to go to that concert tuesday night but if we say no, that will hurt s feelings. we rationalize that if we are always saying yes to our spouses ideas and desires, then our relationship will be peaceful. in loving relationships there should be plenty of nos. being able to say no means you have the courage in what you believe and you have the faith that your honest communication will make your relationship stronger in the long run. if you dont say no when you really wanted to, resentment often follows. here are just a few situations where saying no helps to build a blissful relationship. + no, i dont want to spend my entire vacation with your brother and sisterinlaw. i rather spend most of it with only you and the kids. + no, im not interested in seeing that movie. i had bad dreams for weeks the last time i saw one like that. + no, i dont want a new carcruisetvdiamond ring. i appreciate the gesture but we are already paying too much in interest on all our debts. how about we spend some of that money paying off some bills instead. that would make me much happier. + no, i wont have us in a long distance marriage. we desperately need more time together, not less. now notice that a no response should often be followed up with a reason why you are saying no. otherwise, you can come across as just being difficult. learn to say no. it will keep your relationship out of harms way. how to know if a man really loves you 7 simple questions that prove how he really feels answer these questions and you will instantly know if any guy is a keeper... or needs to be tossed. michael webb o o o o o o o o o o o o o michael webb is athenas loving husband. bestselling author over a dozen books. media celebrity over 500 tv radio appearances. founder, theromantic.com. founder, national resurrect romance week 2nd week in august. founder, love one another charitable foundation .......................................................... y o u r s u b s c r i p t i o n our records indicate that at dirishev@gmail.com requested information by email from our company at date january 13, 2012 ip 135.196.99.183 po box 1567, cary, nc 27512, usa to unsubscribe or change subscriber options visit',\n",
       " 0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[1], y_train.iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    average_precision_score\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Ensure X_train and X_test are lists of strings\n",
    "X_train = X_train.tolist() if isinstance(X_train, pd.Series) else X_train\n",
    "X_test = X_test.tolist() if isinstance(X_test, pd.Series) else X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = int(self.labels.iloc[idx])\n",
    "        # Rest of your code remains the same\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),  # Shape: (max_length,)\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),  # Shape: (max_length,)\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8  # Adjust based on your hardware capabilities\n",
    "\n",
    "train_dataset = TextDataset(X_train, y_train, tokenizer)\n",
    "test_dataset = TextDataset(X_test, y_test, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps')\n",
    "model.to(device)\n",
    "class_weights = class_weights.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/diasirishev/miniforge3/envs/bert_metal/lib/python3.12/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Define loss function with class weights\n",
    "loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, loss_fn, optimizer, device):\n",
    "    model = model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in tqdm(data_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "        loss = loss_fn(outputs.logits, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return total_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader, device):\n",
    "    model = model.eval()\n",
    "    y_preds = []\n",
    "    y_true = []\n",
    "    y_scores = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "\n",
    "            logits = outputs.logits\n",
    "            probabilities = torch.softmax(logits, dim=1)\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "\n",
    "            y_preds.extend(preds.cpu().numpy())\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_scores.extend(probabilities[:, 1].cpu().numpy())\n",
    "\n",
    "    return y_true, y_preds, y_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2327/2327 [21:29<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.2981\n",
      "Validation Recall: 0.5600, Precision: 0.3011, F1-Score: 0.3916, Accuracy: 0.9626\n",
      "Validation ROC AUC: 0.9036, PR AUC: 0.3080\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "EPOCHS = 1  # Adjust based on performance\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "    train_loss = train_epoch(model, train_loader, loss_fn, optimizer, device)\n",
    "    print(f'Train loss: {train_loss:.4f}')\n",
    "\n",
    "    y_true, y_preds, y_scores = eval_model(model, test_loader, device)\n",
    "    recall = recall_score(y_true, y_preds)\n",
    "    precision = precision_score(y_true, y_preds, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_preds, zero_division=0)\n",
    "    accuracy = (np.array(y_preds) == np.array(y_true)).mean()\n",
    "    roc_auc = roc_auc_score(y_true, y_scores)\n",
    "    pr_auc = average_precision_score(y_true, y_scores)\n",
    "\n",
    "    print(f'Validation Recall: {recall:.4f}, Precision: {precision:.4f}, F1-Score: {f1:.4f}, Accuracy: {accuracy:.4f}')\n",
    "    print(f'Validation ROC AUC: {roc_auc:.4f}, PR AUC: {pr_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2326.5"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "email_assistance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
